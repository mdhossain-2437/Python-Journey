# LLModel-Forge Environment Configuration
# Copy this file to .env and update values for your environment

# ==================== SERVER ====================
NODE_ENV=development
PORT=5000

# ==================== DATABASE ====================
# PostgreSQL connection string
DATABASE_URL=postgresql://postgres:llmforge123@localhost:5432/llmforge

# ==================== AUTHENTICATION ====================
# JWT secret key - CHANGE THIS IN PRODUCTION!
JWT_SECRET=your-super-secret-jwt-key-change-in-production-minimum-32-chars

# Session expiry (in days)
JWT_EXPIRES_IN=7d

# ==================== REDIS ====================
# Redis connection for caching and real-time features
REDIS_URL=redis://localhost:6379

# ==================== FILE STORAGE (MinIO/S3) ====================
# MinIO/S3-compatible storage for model files
MINIO_ENDPOINT=localhost
MINIO_PORT=9000
MINIO_ACCESS_KEY=llmforge
MINIO_SECRET_KEY=llmforge123
MINIO_USE_SSL=false
MINIO_BUCKET_MODELS=models
MINIO_BUCKET_DATASETS=datasets
MINIO_BUCKET_ARTIFACTS=artifacts

# For AWS S3 instead of MinIO:
# AWS_ACCESS_KEY_ID=your-aws-access-key
# AWS_SECRET_ACCESS_KEY=your-aws-secret-key
# AWS_REGION=us-east-1
# S3_BUCKET=llmodel-forge-bucket

# ==================== EMAIL (SMTP) ====================
# Email configuration for notifications
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_SECURE=false
SMTP_USER=your-email@gmail.com
SMTP_PASS=your-app-password
SMTP_FROM=LLModel-Forge <noreply@llmodel-forge.com>

# ==================== OAUTH (Optional) ====================
# GitHub OAuth for integrations
GITHUB_CLIENT_ID=your-github-client-id
GITHUB_CLIENT_SECRET=your-github-client-secret

# Google OAuth
GOOGLE_CLIENT_ID=your-google-client-id
GOOGLE_CLIENT_SECRET=your-google-client-secret

# ==================== EXTERNAL SERVICES (Optional) ====================
# Slack webhook for notifications
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/xxx/yyy/zzz

# Sentry for error tracking
SENTRY_DSN=https://xxx@sentry.io/yyy

# ==================== ML CONFIGURATION ====================
# Maximum model file size (in MB)
MAX_MODEL_SIZE_MB=500

# Maximum concurrent training jobs
MAX_CONCURRENT_JOBS=5

# Model inference timeout (in seconds)
INFERENCE_TIMEOUT_SECONDS=30

# ==================== RATE LIMITING ====================
# API rate limiting
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100

# ==================== DOCKER (for docker-compose) ====================
POSTGRES_PASSWORD=llmforge123

